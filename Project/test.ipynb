{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download directory already exists: ../downloads\n",
      "File MovieSummaries already exists in the download directory.\n",
      "File README.txt does not match any expected data file.\n",
      "All files have been loaded as DataFrame attributes.\n",
      "    Number_of_Actors  Movie_Count\n",
      "0                  1         8810\n",
      "1                  2         6690\n",
      "2                  3         5917\n",
      "3                  4         5165\n",
      "5                  5         4244\n",
      "..               ...          ...\n",
      "63                71            1\n",
      "58                72            1\n",
      "47                81            2\n",
      "55                87            1\n",
      "66               115            1\n",
      "\n",
      "[67 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Movie Data Analysis Module\n",
    "This module provides functionality for downloading, extracting, and analyzing movie data.\n",
    "It includes a MovieDataAnalyzer class that handles downloading data from a specified URL\n",
    "and extracting it for further analysis.\n",
    "The module allows for efficient management of movie datasets by:\n",
    "- Checking if data has already been downloaded to avoid redundant downloads\n",
    "- Creating necessary directory structures for data storage\n",
    "- Downloading data from specified URLs\n",
    "- Extracting compressed data files (tar.gz format)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MovieDataAnalyzer:\n",
    "    \"\"\"Class for downloading and analyzing movie data.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MovieDataAnalyzer class.\n",
    "\n",
    "        Args:\n",
    "            data_url: URL of the data file to download\n",
    "        \"\"\"\n",
    "        # Set the data URL\n",
    "        data_url = 'http://www.cs.cmu.edu/~ark/personas/data/MovieSummaries.tar.gz'\n",
    "\n",
    "        # Set the download directory\n",
    "        download_dir: str = '../downloads'\n",
    "\n",
    "        # Create the download directory if it doesn't exist\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "            print(f\"Created download directory: {download_dir}\")\n",
    "        else:\n",
    "            print(f\"Download directory already exists: {download_dir}\")\n",
    "\n",
    "        # Download if file does not exist in the download directory\n",
    "        tar_file_name = os.path.basename(data_url) # Extract the file name from the URL\n",
    "        tar_path = os.path.join(download_dir, tar_file_name)\n",
    "        file_name = os.path.splitext(os.path.splitext(tar_file_name)[0])[0]\n",
    "        dir_path: str = os.path.join(download_dir, file_name)\n",
    "        if not os.path.exists(dir_path):\n",
    "            # Download the file\n",
    "            response = requests.get(data_url, stream=True, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            print(f\"Downloading {tar_file_name}...\")\n",
    "\n",
    "            with open(tar_path, mode='wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "            print(\"Download complete.\")\n",
    "\n",
    "            # Extract the tarball\n",
    "            print(f\"Extracting {file_name}...\")\n",
    "            with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "                tar.extractall(path=download_dir, filter=\"data\")\n",
    "            print(\"Extraction complete.\")\n",
    "        else:\n",
    "            print(f\"File {os.path.basename(dir_path)} already exists in the download directory.\")\n",
    "\n",
    "        # Read the datasets into corresponding dataframes\n",
    "        self.movie_metadata = None\n",
    "        self.character_metadata = None\n",
    "        self.name_clusters = None\n",
    "        self.plot_summaries = None\n",
    "        self.tvtropes_clusters = None\n",
    "\n",
    "        # Read each TSV file and create a DataFrame\n",
    "        for file in os.listdir(dir_path):\n",
    "            if file == \"character.metadata.tsv\":\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                ###\n",
    "                #Column names from README:\n",
    "                # 1. Wikipedia movie ID, 2. Freebase movie ID, 3. Movie release date,\n",
    "                # 4. Character name, 5. Actor date of birth, 6. Actor gender,\n",
    "                # 7. Actor height (in meters), 8. Actor ethnicity (Freebase ID),\n",
    "                # 9. Actor name, 10. Actor age at movie release,\n",
    "                # 11. Freebase character/actor map ID, # 12. Freebase character ID,\n",
    "                # 13. Freebase actor ID\n",
    "                ###\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", names=[\n",
    "                    \"wikipedia_movie_id\", \"freebase_movie_id\", \"movie_release_date\", \n",
    "                    \"character_name\", \"actor_date_of_birth\", \"actor_gender\", \"actor_height\", \n",
    "                    \"actor_ethnicity\", \"actor_name\", \"actor_age_at_movie_release\", \n",
    "                    \"freebase_character_actor_map_id\", \"freebase_character_id\", \n",
    "                    \"freebase_actor_id\"\n",
    "                ], encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "                self.characters = df  # Store as an attribute\n",
    "            elif file == \"movie.metadata.tsv\":\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                ###\n",
    "                #Column names from README:\n",
    "                # 1. Wikipedia movie ID, 2. Freebase movie ID, 3. Movie name, 4. Movie release date,\n",
    "                # 5. Movie box office revenue, 6. Movie runtime,\n",
    "                # 7. Movie languages (Freebase ID:name tuples),\n",
    "                # 8. Movie countries (Freebase ID:name tuples),\n",
    "                # 9. Movie genres (Freebase ID:name tuples)\n",
    "                ###\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", names=[\n",
    "                    \"wikipedia_movie_id\", \"freebase_movie_id\", \"movie_name\", \"movie_release_date\", \n",
    "                    \"movie_box_office_revenue\", \"movie_runtime\", \"movie_languages\", \n",
    "                    \"movie_countries\", \"movie_genres\"\n",
    "                ], encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "                self.movie_metadata = df  # Store as an attribute\n",
    "            elif file == \"name.clusters.txt\":\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                ### Column names from README: 1. Name, 2. Actor ID\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", names=[\"name\", \"actor_id\"],\n",
    "                                  encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "                self.name_clusters = df\n",
    "            elif file == \"plot_summaries.txt\":\n",
    "                ### Column names from README: 1. Wikipedia movie ID, 2. Plot summary\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", names=[\"movie_id\", \"summary\"],\n",
    "                                 encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "                self.plot_summaries = df  # Store as an attribute\n",
    "            elif file == \"tvtropes.clusters.txt\":\n",
    "                ### Column names from README: Cluster ID and Name\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", names=[\"name\", \"cluster\"],\n",
    "                                 encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "                self.tvtropes_clusters = df  # Store as an attribute\n",
    "            else:\n",
    "                print(f\"File {file} does not match any expected data file.\")\n",
    "        print(\"All files have been loaded as DataFrame attributes.\")\n",
    "\n",
    "    def movie_type(self, N: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate the N most common types of movies and their counts.\n",
    "\n",
    "        Args:\n",
    "            N (int): Number of top movie types to return. Default is 10.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with columns \"Movie_Type\" and \"Count\" for the top N movie types.\n",
    "        \"\"\"\n",
    "        if not isinstance(N, int):\n",
    "            raise TypeError(\"N must be an integer\")\n",
    "\n",
    "        # Split the movie genres into individual genres\n",
    "        genres = self.movie_metadata['movie_genres'].str.split(',').explode()\n",
    "\n",
    "        # Count the occurrences of each genre\n",
    "        genre_counts = genres.value_counts().head(N).reset_index()\n",
    "        genre_counts.columns = ['Movie_Type', 'Count']\n",
    "\n",
    "        return genre_counts\n",
    "    \n",
    "    def actor_count(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate a histogram of the number of actors vs movie counts.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with columns \"Number_of_Actors\" and \"Movie_Count\".\n",
    "        \"\"\"\n",
    "        # Group by movie ID and count the number of actors per movie\n",
    "        actor_counts = self.characters.groupby('wikipedia_movie_id').size()\n",
    "\n",
    "        # Create a histogram of the actor counts\n",
    "        actor_histogram = actor_counts.value_counts().reset_index()\n",
    "        actor_histogram.columns = ['Number_of_Actors', 'Movie_Count']\n",
    "        actor_histogram = actor_histogram.sort_values(by='Number_of_Actors')\n",
    "\n",
    "        return actor_histogram\n",
    "\n",
    "# Create an instance of the MovieDataAnalyzer class\n",
    "analyzer = MovieDataAnalyzer()\n",
    "\n",
    "# Test actor_count method\n",
    "actor_hist = analyzer.actor_count()\n",
    "print(actor_hist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
